{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6938870,"sourceType":"datasetVersion","datasetId":3984823}],"dockerImageVersionId":30582,"isInternetEnabled":false,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) # metapackage of all tidyverse packages\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2023-11-17T18:15:31.005443Z","iopub.execute_input":"2023-11-17T18:15:31.070065Z","iopub.status.idle":"2023-11-17T18:15:31.107990Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":"'e-commerce-churn-dataset'","text/markdown":"'e-commerce-churn-dataset'","text/latex":"'e-commerce-churn-dataset'","text/plain":"[1] \"e-commerce-churn-dataset\""},"metadata":{}}]},{"cell_type":"code","source":"# Load data from CSV file\ndata <- read.csv(\"/kaggle/input/e-commerce-churn-dataset/churn_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-17T18:15:35.836072Z","iopub.execute_input":"2023-11-17T18:15:35.838414Z","iopub.status.idle":"2023-11-17T18:15:35.941008Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data <- data[, !names(data) %in% 'CustomerID', drop = FALSE]\n\n#missing values\nmissing_values <- colSums(is.na(data))\n\n#fill those missing values\n\n# Loop through columns\nfor (col in names(data)) {\n  # Check if there are missing values in the column\n  if (sum(is.na(data[[col]])) > 0) {\n    # Fill missing values with the median of the column\n    data[[col]][is.na(data[[col]])] <- median(data[[col]], na.rm = TRUE)\n  }\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-17T18:16:07.060763Z","iopub.execute_input":"2023-11-17T18:16:07.064408Z","iopub.status.idle":"2023-11-17T18:16:07.104482Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Assuming your data frame is named 'df'\n\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(caret)\n\n# Convert categorical variables into numerical variables using label encoding\ndata$PreferredLoginDevice <- as.numeric(as.factor(data$PreferredLoginDevice))\ndata$PreferredPaymentMode <- as.numeric(as.factor(data$PreferredPaymentMode))\ndata$Gender <- as.numeric(as.factor(data$Gender))\ndata$PreferedOrderCat <- as.numeric(as.factor(data$PreferedOrderCat))\ndata$MaritalStatus <- as.numeric(as.factor(data$MaritalStatus))\n\n# Split the dataset into training and testing datasets\nset.seed(42)  # Setting seed for reproducibility\nsplitIndex <- createDataPartition(data$Churn, p = 0.7, list = FALSE)\ntrain_data <- data[splitIndex, ]\ntest_data <- data[-splitIndex, ]\n\n# Separate predictor variables (X) and response variable (y)\nX_train <- train_data[, !(names(train_data) %in% c(\"CustomerID\", \"Churn\"))]\ny_train <- train_data$Churn\nX_test <- test_data[, !(names(test_data) %in% c(\"CustomerID\", \"Churn\"))]\ny_test <- test_data$Churn","metadata":{"execution":{"iopub.status.busy":"2023-11-17T18:18:44.797024Z","iopub.execute_input":"2023-11-17T18:18:44.799230Z","iopub.status.idle":"2023-11-17T18:18:44.890269Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\n\nlibrary(stats)\n\n# Create a logistic regression model\nlogreg <- glm(y_train ~ ., family = binomial, data = cbind(y_train, X_train))\n\n# Make predictions on the test set\nlogreg_prediction <- predict(logreg, newdata = cbind(y_test, X_test), type = \"response\") > 0.5\n\n# Print accuracy score\naccuracy <- sum(logreg_prediction == y_test) / length(y_test)\ncat('Accuracy Score:', accuracy, '\\n')\n\n# Print classification report\ntable_true_pred <- table(y_test, logreg_prediction)\nprint('Confusion Matrix:')\nprint(table_true_pred)\n\nprecision <- table_true_pred[2, 2] / sum(table_true_pred[, 2])\nrecall <- table_true_pred[2, 2] / sum(table_true_pred[2, ])\nf1_score <- 2 * (precision * recall) / (precision + recall)\n\ncat('\\nClassification Report:\\n')\ncat('  Precision: ', precision, '\\n')\ncat('  Recall: ', recall, '\\n')\ncat('  F1-Score: ', f1_score, '\\n')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T18:22:42.644172Z","iopub.execute_input":"2023-11-17T18:22:42.646331Z","iopub.status.idle":"2023-11-17T18:22:42.864748Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Accuracy Score: 0.8809947 \n[1] \"Confusion Matrix:\"\n      logreg_prediction\ny_test FALSE TRUE\n     0  1363   53\n     1   148  125\n\nClassification Report:\n  Precision:  0.7022472 \n  Recall:  0.4578755 \n  F1-Score:  0.5543237 \n","output_type":"stream"}]}]}